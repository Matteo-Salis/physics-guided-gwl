{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray\n",
    "import rioxarray\n",
    "import fiona\n",
    "\n",
    "#import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from rasterio.enums import Resampling\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtd_csv_path = \"/leonardo_work/IscrC_DL4EO/trials/data/dataset_wtd_roi.csv\"\n",
    "meteo_nc_path = \"/leonardo_work/IscrC_DL4EO/trials/data/meteo_bucket_model_snowpack_ROI_1958_2023.nc\"\n",
    "wtd_stations_shp_path = \"/leonardo_work/IscrC_DL4EO/trials/data/shapefile/underground_wtd_sensor_roi.shp\"\n",
    "dtm_nc_path = \"/leonardo_work/IscrC_DL4EO/trials/data/dtm_ROI.nc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ContinuousDataset(Dataset):\n",
    "    \"\"\"Weather and WTD Dataset for the continuous case model\"\"\"\n",
    "\n",
    "    def __init__(self, dict_files, #meteo_nc_path, wtd_csv_path, wtd_stations_shp_path,\n",
    "                 fill_value = 0,\n",
    "                 transform = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dict_files (string): Path to the .nc file.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                    on a sample.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Attributes init\n",
    "        self.dict_files = dict_files\n",
    "        self.timesteps = self.dict_files[\"timesteps\"]\n",
    "\n",
    "        # Meteorological data loading \n",
    "        self.loading_weather()\n",
    "        \n",
    "        # Digital Terrain Model data loading\n",
    "        self.loading_dtm()\n",
    "        \n",
    "        # Water Table Depth data loading \n",
    "        self.loading_point_wtd(fill_value = fill_value)\n",
    "\n",
    "        # Transform       \n",
    "        self.transform = transform\n",
    "        \n",
    "    def loading_dtm(self):\n",
    "        self.dtm_roi = rioxarray.open_rasterio(self.dict_files[\"dtm_nc\"],\n",
    "                                               engine='fiona')\n",
    "        self.dtm_roi = self.dtm_roi.rio.write_crs(\"epsg:4326\")\n",
    "        \n",
    "            \n",
    "    def loading_weather(self):\n",
    "        self.weather_xr = xarray.open_dataset(self.dict_files[\"weather_nc_path\"])\n",
    "        self.weather_xr = self.weather_xr.rio.write_crs(\"epsg:4326\")\n",
    "        \n",
    "        # Compute coord matrix\n",
    "        lat_matrix = np.vstack([self.weather_xr.lat.values for i in range(len(self.weather_xr.lon.values))]).transpose()\n",
    "        lon_matrix = np.vstack([self.weather_xr.lon.values for i in range(len(self.weather_xr.lat.values))])\n",
    "        self.weather_coords = np.stack([lat_matrix,lon_matrix], axis = -1)\n",
    "        \n",
    "\n",
    "    def loading_point_wtd(self, fill_value = 0):\n",
    "        \n",
    "        # Water Table Depth data loading\n",
    "        self.wtd_df = pd.read_csv(self.dict_files[\"wtd_csv_path\"], \n",
    "                                    dtype= {\"sensor_id\": \"str\"})\n",
    "        self.wtd_df = self.wtd_df.astype({\"date\":'datetime64[ns]'})\n",
    "\n",
    "        # Water Table Depth Sensors shapefile loading: \n",
    "        self.wtd_names = gpd.read_file(self.dict_files[\"wtd_shp\"],\n",
    "                                             engine='fiona')\n",
    "        self.wtd_names = self.wtd_names.to_crs('epsg:4326')\n",
    "\n",
    "        # Define attributes about dates and coordinates\n",
    "        self.dates = self.wtd_df[\"date\"].unique()\n",
    "        self.sensor_id_list = self.wtd_df[\"sensor_id\"].unique()\n",
    "        \n",
    "        \n",
    "        ### Merge csv and shp into a joint spatio temporal representation\n",
    "        sensor_coord_x_list = []\n",
    "        sensor_coord_y_list = []\n",
    "\n",
    "        # Retrieve coordinates from id codes\n",
    "        for sensor in self.sensor_id_list:\n",
    "            coord_x = self.wtd_names.loc[self.wtd_names[\"sensor_id\"] == sensor].geometry.x.values[0]\n",
    "            coord_y = self.wtd_names.loc[self.wtd_names[\"sensor_id\"] == sensor].geometry.y.values[0]\n",
    "            sensor_coord_x_list.append(coord_x)\n",
    "            sensor_coord_y_list.append(coord_y)\n",
    "\n",
    "        # Buil a dictionary of coordinates and id codes\n",
    "        from_id_to_coord_x_dict = {self.sensor_id_list[i]: sensor_coord_x_list[i] for i in range(len(sensor_coord_x_list))}\n",
    "        from_id_to_coord_y_dict = {self.sensor_id_list[i]: sensor_coord_y_list[i] for i in range(len(sensor_coord_y_list))}\n",
    "\n",
    "        # Map id codes to coordinates for all rows in the original ds\n",
    "        queries = list(self.wtd_df[\"sensor_id\"].values)\n",
    "        coordinates_x = itemgetter(*queries)(from_id_to_coord_x_dict)\n",
    "        coordinates_y = itemgetter(*queries)(from_id_to_coord_y_dict)\n",
    "\n",
    "        # insert new columns containing coordinates\n",
    "        self.wtd_df[\"x\"] = coordinates_x\n",
    "        self.wtd_df[\"y\"] = coordinates_y\n",
    "        \n",
    "        self.wtd_df = self.wtd_df.set_index([\"date\",\"y\",\"x\"])\n",
    "        \n",
    "        # Subset wtd data truncating the last `timestep` instances\n",
    "        last_date = self.dates.max() - np.timedelta64(self.timesteps, 'D')\n",
    "        self.input_dates = self.dates[self.dates <= last_date]\n",
    "        \n",
    "        # Create nan-mask\n",
    "        self.wtd_df[\"nan_mask\"] = 1*~self.wtd_df[\"wtd\"].isna()\n",
    "        self.wtd_df[\"wtd\"] = self.wtd_df[\"wtd\"].fillna(fill_value)\n",
    "        \n",
    "    def __len__(self):\n",
    "        data = self.wtd_df.loc[pd.IndexSlice[self.wtd_df.index.get_level_values(0) <= self.input_dates.max(),\n",
    "                                                       :,\n",
    "                                                       :]]\n",
    "        return len(data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if idx < 0:\n",
    "            idx = self.__len__() + idx\n",
    "        \n",
    "        # Retrieve date and coords for idx instance\n",
    "        start_date = self.wtd_df.iloc[idx, :].name[0]\n",
    "        sample_lat = self.wtd_df.iloc[idx, :].name[1]\n",
    "        sample_lon = self.wtd_df.iloc[idx, :].name[2]\n",
    "        sample_dtm = self.dtm_roi.sel(x = sample_lon,\n",
    "                                      y = sample_lat,\n",
    "                                      method = \"nearest\").values  \n",
    "        \n",
    "        end_date = start_date + np.timedelta64(self.timesteps, \"D\")\n",
    "        \n",
    "        # print(\"start date: \", str(start_date))\n",
    "        # print(\"end date: \", str(end_date))\n",
    "        \n",
    "        # Initial state WTD (t0) data\n",
    "        wtd_t0 = self.wtd_df[[\"wtd\", \"nan_mask\"]].loc[self.wtd_df.index.get_level_values(0) == start_date]\n",
    "        wtd_t0_values = wtd_t0[\"wtd\"].values\n",
    "        wtd_t0_mask = wtd_t0[\"nan_mask\"].values\n",
    "        wtd_t0_lat = wtd_t0.index.get_level_values(1).values\n",
    "        wtd_t0_lon = wtd_t0.index.get_level_values(2).values\n",
    "        wtd_t0_dtm = np.array([self.dtm_roi.sel(x = wtd_t0_lon[sensor],\n",
    "                                                y = wtd_t0_lat[sensor],\n",
    "                                                method = \"nearest\") for sensor in range(len(wtd_t0_lat))]).squeeze()\n",
    "        \n",
    "        #wtd_t0_mask = 1*~np.isnan(wtd_t0_values)\n",
    "        X = [torch.from_numpy(wtd_t0_lat).to(torch.float32),\n",
    "             torch.from_numpy(wtd_t0_lon).to(torch.float32),\n",
    "             torch.from_numpy(wtd_t0_dtm).to(torch.float32),\n",
    "             torch.from_numpy(wtd_t0_values).to(torch.float32),\n",
    "             torch.from_numpy(wtd_t0_mask).to(torch.float32)]\n",
    "        X = torch.stack(X, dim = -1)\n",
    "        \n",
    "        Z = [torch.tensor(sample_lat).reshape(1).to(torch.float32),\n",
    "             torch.tensor(sample_lon).reshape(1).to(torch.float32),\n",
    "             torch.tensor(sample_dtm).reshape(1).to(torch.float32)]\n",
    "        \n",
    "        Z = torch.stack(Z, dim = -1)\n",
    "        \n",
    "        # Retrieve weather data\n",
    "        weather_video = self.weather_xr.sel(time = slice(start_date + np.timedelta64(1, \"D\"),\n",
    "                                                    end_date)) #slice include extremes\n",
    "        weather_video = weather_video.to_array().values\n",
    "        W = [torch.from_numpy(weather_video).to(torch.float32),\n",
    "             torch.from_numpy(self.weather_coords).to(torch.float32)]\n",
    "        \n",
    "        # Retrieve wtd values from t0+1 to T for the idx instance sensor\n",
    "        wtd_t1_T = self.wtd_df[[\"wtd\", \"nan_mask\"]].loc[(self.wtd_df.index.get_level_values(0) > start_date) &\n",
    "                                          (self.wtd_df.index.get_level_values(0) <= end_date)  & \n",
    "                                          (self.wtd_df.index.get_level_values(1) == sample_lat)&\n",
    "                                          (self.wtd_df.index.get_level_values(2) == sample_lon)]\n",
    "        \n",
    "        wtd_t1_T_values =  wtd_t1_T[\"wtd\"].values\n",
    "        wtd_t1_T_mask =  wtd_t1_T[\"nan_mask\"].values        \n",
    "        \n",
    "        Y = [torch.from_numpy(wtd_t1_T_values).to(torch.float32),\n",
    "             torch.from_numpy(wtd_t1_T_mask).to(torch.float32)]\n",
    "        \n",
    "        Y = torch.stack(Y, dim = -1)\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return [X, Z, W, Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_files = {\n",
    "    \"wtd_csv_path\" : \"/leonardo_work/IscrC_DL4EO/trials/data/dataset_wtd_roi.csv\",\n",
    "    \"weather_nc_path\" : \"/leonardo_work/IscrC_DL4EO/trials/data/meteo_bucket_model_snowpack_ROI_1958_2023.nc\",\n",
    "    \"wtd_shp\" : \"/leonardo_work/IscrC_DL4EO/trials/data/shapefile/underground_wtd_sensor_roi.shp\",\n",
    "    \"piedmont_shp\" : \"/leonardo_work/IscrC_DL4EO/trials/data/shapefile/piemonte_admin_boundaries.shp\",\n",
    "    \"dtm_nc\" : \"/leonardo_work/IscrC_DL4EO/trials/data/dtm_ROI.nc\",\n",
    "    \"timesteps\" : 180\n",
    "}\n",
    "\n",
    "ds = ContinuousDataset(dict_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the dataset: 311457\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of the dataset: {ds.__len__()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "class Continuous1DNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 timestep = 180,\n",
    "                 num_sensor = 31,\n",
    "                 lstm_layer = 3,\n",
    "                 lstm_input_units = 16,\n",
    "                 lstm_units = 32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.timestep = timestep\n",
    "        self.lstm_layer = lstm_layer\n",
    "        self.lstm_input_units = lstm_input_units\n",
    "        self.lstm_units = lstm_units\n",
    "        self.num_sensor = num_sensor\n",
    "        \n",
    "        # Conditioning block - gate fashion        \n",
    "        # Values embedding\n",
    "        cb_vemb = []\n",
    "        cb_vemb.append(nn.Linear(2, 1))\n",
    "        cb_vemb.append(nn.ReLU())\n",
    "        self.cb_vemb = nn.Sequential(*cb_vemb)\n",
    "        # Coordinates embedding\n",
    "        cb_cemb = []\n",
    "        cb_cemb.append(nn.Linear(3, 1))\n",
    "        cb_cemb.append(nn.ReLU())\n",
    "        self.cb_cemb = nn.Sequential(*cb_cemb)\n",
    "        \n",
    "        self.cb_softmax = nn.Softmax(dim = 1)\n",
    "        # Fully connected\n",
    "        cb_fc = []\n",
    "        cb_fc.append(nn.Linear(self.num_sensor, 32))\n",
    "        cb_fc.append(nn.ReLU())\n",
    "        cb_fc.append(nn.Linear(32, 32))\n",
    "        cb_fc.append(nn.ReLU())\n",
    "        cb_fc.append(nn.Linear(32, 32))\n",
    "        cb_fc.append(nn.ReLU())\n",
    "        cb_fc.append(nn.Linear(32, self.lstm_units))\n",
    "        cb_fc.append(nn.ReLU())\n",
    "        self.cb_fc = nn.Sequential(*cb_fc)\n",
    "        \n",
    "        # Weather block\n",
    "        conv3d_stack=[]\n",
    "        conv3d_stack.append(nn.Conv3d(12, 32, (1,2,2))) # Conv input (N, C, D, H, W) - kernel 3d (D, H, W)\n",
    "        conv3d_stack.append(nn.BatchNorm3d(32))\n",
    "        conv3d_stack.append(nn.ReLU())\n",
    "        \n",
    "        for i in range(4):\n",
    "            conv3d_stack.append(nn.Conv3d(32, 32, (1,2,2)))\n",
    "            conv3d_stack.append(nn.BatchNorm3d(32))\n",
    "            conv3d_stack.append(nn.ReLU())\n",
    "            \n",
    "        conv3d_stack.append(nn.AdaptiveAvgPool3d((None,4,4)))\n",
    "        conv3d_stack.append(nn.Conv3d(32, 32, (1,2,2)))\n",
    "        conv3d_stack.append(nn.BatchNorm3d(32))\n",
    "        conv3d_stack.append(nn.ReLU())\n",
    "        conv3d_stack.append(nn.Conv3d(32, 32, (1,2,2)))\n",
    "        conv3d_stack.append(nn.BatchNorm3d(32))\n",
    "        conv3d_stack.append(nn.ReLU())\n",
    "        conv3d_stack.append(nn.Conv3d(32, self.lstm_input_units, (1,2,2)))\n",
    "        conv3d_stack.append(nn.BatchNorm3d(self.lstm_input_units))\n",
    "        conv3d_stack.append(nn.ReLU())\n",
    "        self.conv3d_stack = nn.Sequential(*conv3d_stack)\n",
    "            \n",
    "        # Joint sequental block\n",
    "        self.lstm_1 = nn.LSTM(self.lstm_input_units, self.lstm_units,\n",
    "                              batch_first=True,\n",
    "                              num_layers=self.lstm_layer) # Batch first input (N,L,H)\n",
    "        \n",
    "        fc = []\n",
    "        fc.append(nn.Linear(self.lstm_units, 8))\n",
    "        fc.append(nn.ReLU())\n",
    "        fc.append(nn.Linear(8, 1))\n",
    "        self.fc = nn.Sequential(*fc)\n",
    "\n",
    "\n",
    "    def forward(self, x, z, w):\n",
    "        \"\"\"\n",
    "        input : x (31, 5); z (1, 3); w[0] (10, 180, 9, 12); w[1] (9, 12, 2)\n",
    "        return \n",
    "            lstm_out (array): lstm_out = [S_we, M, P_r, Es, K_s, K_r]\n",
    "        x: tensor of shape (L,Hin) if minibatches itaration (L,N,Hin) when batch_first=False (default)\n",
    "        \"\"\"\n",
    "        \n",
    "        # #x (31, 5); z (1, 3); w[0] (10, 180, 9, 12); w[1] (9, 12, 2); y (180, 2)\n",
    "        # [wtd_t0_lat, wtd_t0_lon,\n",
    "        #  wtd_t0_dtm, wtd_t0_values,\n",
    "        #  wtd_t0_mask] = x\n",
    "        \n",
    "        # [sample_lat, sample_lon, sample_dtm] = z\n",
    "        \n",
    "        \n",
    "        # Conditioning block\n",
    "        cb_value_emb = self.cb_vemb(x[:,:,3:])\n",
    "        \n",
    "        cb_coord_emb = torch.cat((x[:,:,:3], z), dim = 1)\n",
    "        cb_coord_emb = self.cb_cemb(cb_coord_emb)\n",
    "        cb_coord_emb_s = cb_coord_emb[:,:x[:,:,:3].shape[1],:]\n",
    "        cb_coord_emb_p = cb_coord_emb[:,-1,:].unsqueeze(dim = 1)\n",
    "        cb_coord_emb = 1-self.cb_softmax(cb_coord_emb_s - cb_coord_emb_p) \n",
    "        \n",
    "        cb_wtd0 = torch.mul(cb_value_emb, cb_coord_emb)\n",
    "        cb_wtd0 = torch.movedim(cb_wtd0, 1, -1)\n",
    "        cb_wtd0 = self.cb_fc(cb_wtd0)\n",
    "        \n",
    "        # Weather block\n",
    "        ## w[0] (10, 180, 9, 12); w[1] (9, 12, 2)\n",
    "        ## Compute distances\n",
    "        weather_distances_lat = w[1][:,:,:,0] - z[:,:,0].unsqueeze(-1)\n",
    "        weather_distances_lat = weather_distances_lat[None, None, ...].expand([self.timestep,\n",
    "                                                                           -1,-1,-1,-1])\n",
    "        weather_distances_lat = torch.movedim(weather_distances_lat,\n",
    "                                              (0,2), (2,0))\n",
    "        \n",
    "        weather_distances_lon = w[1][:,:,:,1] - z[:,:,1].unsqueeze(-1)\n",
    "        weather_distances_lon = weather_distances_lon[None, None, ...].expand([self.timestep,\n",
    "                                                                           -1,-1,-1,-1])\n",
    "        weather_distances_lon = torch.movedim(weather_distances_lon,\n",
    "                                              (0,2), (2,0))\n",
    "        ## Concat with w[0] and forward\n",
    "        weather_video = torch.cat((w[0], weather_distances_lat, weather_distances_lon), dim = 1)\n",
    "        \n",
    "        wb_td3dconv = self.conv3d_stack(weather_video)\n",
    "        \n",
    "        wb_td3dconv = wb_td3dconv.squeeze()\n",
    "        wb_td3dconv = torch.moveaxis(wb_td3dconv, 1, -1)\n",
    "        \n",
    "        # Sequential block\n",
    "        cb_wtd0 = cb_wtd0.expand([-1,self.lstm_layer,-1])\n",
    "        cb_wtd0 = torch.movedim(cb_wtd0, 0, 1)\n",
    "        \n",
    "        wtd_series = self.lstm_1(wb_td3dconv,\n",
    "                                 (cb_wtd0.contiguous(),\n",
    "                                  cb_wtd0.contiguous())) #input  [input, (h_0, c_0)] - h and c (Dâˆ—num_layers,N,H)\n",
    "        \n",
    "        wtd_series = self.fc(wtd_series[0])\n",
    "        \n",
    "        return wtd_series.squeeze()\n",
    "\n",
    "model = Continuous1DNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parameters:  56648\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of trainable parameters: \" ,sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 31\n",
    "max_epochs = 100\n",
    "\n",
    "test_split_p = 0.2\n",
    "train_split_p = 1 - test_split_p\n",
    "train_idx = int(ds.__len__()*train_split_p)\n",
    "test_idx = int(ds.__len__()*test_split_p)\n",
    "\n",
    "train_idxs, test_idxs = np.arange(train_idx), np.arange(train_idx, train_idx + test_idx)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idxs)\n",
    "test_sampler = SubsetRandomSampler(test_idxs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=ds,\n",
    "                                            batch_size=batch_size,\n",
    "                                            sampler=train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(iterations, loss, save_dir = None):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.suptitle(\"Loss vs iterations\")\n",
    "    ax.plot(iterations, loss, label = \"loss\")\n",
    "    ax.legend()\n",
    "    if save_dir:\n",
    "        plt.savefig(f\"{save_dir}.png\", bbox_inches = 'tight') #dpi = 400, transparent = True\n",
    "    else:\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "def plot_predictions(x, y, y_hat, save_dir = None):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.suptitle(\"Loss vs iterations\")\n",
    "    ax.plot(x, y_hat, label = \"predicted\")\n",
    "    ax.plot(x, y, label = \"true\")\n",
    "    ax.legend()\n",
    "    if save_dir:\n",
    "        plt.savefig(f\"{save_dir}.png\", bbox_inches = 'tight') #dpi = 400, transparent = True\n",
    "    else:\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse(y_hat, y, mask):\n",
    "    # y_hat = y_hat.to(device)\n",
    "    # y = y.to(device)\n",
    "    # mask = mask.to(device)\n",
    "    return torch.sum(((y_hat-y)*mask)**2.0)  / torch.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/8038 [00:03<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch mem allocated in MB:  0.0\n",
      "After predict mem allocated in MB:  0.0\n",
      "tensor(355.8158, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 1/8038 [00:12<22:46:06, 10.20s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch mem allocated in MB:  0.0\n",
      "After predict mem allocated in MB:  0.0\n",
      "tensor(517.5479, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 1/8038 [00:14<33:22:57, 14.95s/batch]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 30\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n\u001b[1;32m     27\u001b[0m loss_list\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m---> 30\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (batch_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/leonardo_work/IscrC_DL4EO/my_venv/lib/python3.11/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/leonardo_work/IscrC_DL4EO/my_venv/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/leonardo_work/IscrC_DL4EO/my_venv/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "start_time = time.time()\n",
    "loss_list = []\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "save_dir = \"/leonardo_scratch/fast/IscrC_DL4EO/github/water-pinns/src/runs\"\n",
    "\n",
    "for i in range(max_epochs):\n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "            for batch_idx, (x, z, w, y) in enumerate(tepoch):\n",
    "                tepoch.set_description(f\"Epoch {i}\")\n",
    "                \n",
    "                x = x.to(device)\n",
    "                z = z.to(device)\n",
    "                w[0] = w[0].to(device)\n",
    "                w[1] = w[1].to(device)\n",
    "                y = y.to(device)\n",
    "                print('Batch mem allocated in MB: ', torch.cuda.memory_allocated() / 1024**2)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                y_hat = model(x, z, w)\n",
    "                print('After predict mem allocated in MB: ', torch.cuda.memory_allocated() / 1024**2)\n",
    "                loss = masked_mse(y_hat,\n",
    "                                  y[:,:,0],\n",
    "                                  y[:,:,1])\n",
    "                print(loss)\n",
    "                loss_list.append(loss.detach().cpu().numpy())\n",
    "\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "                if (batch_idx+1)%1000 == 0:\n",
    "                    plot_loss(np.arange(len(loss_list)),\n",
    "                          np.array(loss_list),\n",
    "                          save_dir = f\"{save_dir}/loss_{timestamp}\")\n",
    "                \n",
    "                    plot_predictions(np.arange(180),\n",
    "                                 y_hat = y_hat[-1,:].detach().cpu().numpy(),\n",
    "                                 y = y[-1,:,0].detach().cpu().numpy(),\n",
    "                                 save_dir= f\"{save_dir}/pred_{timestamp}\")\n",
    "        \n",
    "            model_path = 'model_{}_{}.pt'.format(timestamp, i)\n",
    "            torch.save(model.state_dict(), f\"{save_dir}/{model_path}\")\n",
    "                    \n",
    "                \n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sketches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova = torch.tensor([[[[0],[0],[0],[0]],\n",
    "                      [[0],[0],[0],[0]]],\n",
    "                      [[[0],[0],[0],[0]],\n",
    "                      [[0],[0],[0],[0]]],\n",
    "                      [[[0],[0],[0],[0]],\n",
    "                      [[0],[0],[0],[0]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 4, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prova.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prova.movedim(0,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.movedim(prova, 0,2).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
