{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray\n",
    "import rioxarray\n",
    "import fiona\n",
    "\n",
    "#import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from rasterio.enums import Resampling\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data.json: {'experiment_name': 'first_pinns_test_1D', 'wandb_dir': '/leonardo_scratch/fast/IscrC_DL4EO/github/water-pinns/src/runs', 'save_model_dir': '/leonardo_scratch/fast/IscrC_DL4EO/github/water-pinns/src/runs/continuous_1d', 'data_dir': '/leonardo_work/IscrC_DL4EO/trials/data/', 'wtd_csv_path': '/leonardo_work/IscrC_DL4EO/trials/data/dataset_wtd_roi.csv', 'weather_nc_path': '/leonardo_work/IscrC_DL4EO/trials/data/meteo_bucket_model_snowpack_ROI_1958_2023.nc', 'wtd_shp': '/leonardo_work/IscrC_DL4EO/trials/data/shapefile/underground_wtd_sensor_roi.shp', 'piedmont_shp': '/leonardo_work/IscrC_DL4EO/trials/data/shapefile/piemonte_admin_boundaries.shp', 'dtm_nc': '/leonardo_work/IscrC_DL4EO/trials/data/dtm_ROI.nc', 'weather_dtm': '/leonardo_work/IscrC_DL4EO/trials/data/dtm_ROI_arpa_weather.nc', 'timesteps': 180, 'test_split_p': 0.2, 'all_dataset': False, 'max_ds_elems': 10000, 'tensorboard': True, 'dataset': 'wtd_weather_2001_2023', 'input_channels': 10, 'input_height': 9, 'input_width': 12, 'shift_pixels': 0, 'augmentation': True, 'model': 'Discrete2DNN', 'start_epoch': 0, 'epochs': 100, 'batch_size': 256, 'optimizer': 'adam', 'lr': 0.00075, 'min_lr': 0, 'decay_rate': 0.99, 'decay_steps': 1, 'monitor': 'loss', 'iter_size': 1, 'patience': 10, 'use_cuda': True, 'cuda_device': 'cuda:0', 'num_workers': 1, 'print_every': 10, 'save_every': 1, 'seeds': [42]}\n"
     ]
    }
   ],
   "source": [
    "json_file = \"/leonardo_scratch/fast/IscrC_DL4EO/github/water-pinns/src/configs/discrete_2D_wtd/test_1D.json\"\n",
    "dict_files = {}\n",
    "with open(json_file) as f:\n",
    "    dict_files = json.load(f)\n",
    "    print(f\"Read data.json: {dict_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ContinuousDataset(Dataset):\n",
    "    \"\"\"Weather and WTD Dataset for the continuous case model\"\"\"\n",
    "\n",
    "    def __init__(self, dict_files, #meteo_nc_path, wtd_csv_path, wtd_stations_shp_path,\n",
    "                 fill_value = 0,\n",
    "                 transform = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dict_files (string): Path to the .nc file.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                    on a sample.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Attributes init\n",
    "        self.dict_files = dict_files\n",
    "        self.timesteps = self.dict_files[\"timesteps\"]\n",
    "\n",
    "        # Meteorological data loading \n",
    "        self.loading_weather()\n",
    "        \n",
    "        # Digital Terrain Model data loading\n",
    "        self.loading_dtm()\n",
    "        \n",
    "        # Water Table Depth data loading \n",
    "        self.loading_point_wtd(fill_value = fill_value)\n",
    "\n",
    "        # Transform       \n",
    "        self.transform = transform\n",
    "        \n",
    "    def loading_dtm(self):\n",
    "        self.dtm_roi = rioxarray.open_rasterio(self.dict_files[\"dtm_nc\"],\n",
    "                                               engine='fiona')\n",
    "        self.dtm_roi = self.dtm_roi.rio.write_crs(\"epsg:4326\")\n",
    "        \n",
    "            \n",
    "    def loading_weather(self):\n",
    "        self.weather_xr = xarray.open_dataset(self.dict_files[\"weather_nc_path\"])\n",
    "        self.weather_xr = self.weather_xr.rio.write_crs(\"epsg:4326\")\n",
    "        \n",
    "        # Compute coord matrix\n",
    "        lat_matrix = np.vstack([self.weather_xr.lat.values for i in range(len(self.weather_xr.lon.values))]).transpose()\n",
    "        lon_matrix = np.vstack([self.weather_xr.lon.values for i in range(len(self.weather_xr.lat.values))])\n",
    "        \n",
    "        self.weather_coords = np.stack([lat_matrix,lon_matrix], axis = -1)\n",
    "        \n",
    "        self.weather_dtm = rioxarray.open_rasterio(self.dict_files[\"weather_dtm\"],\n",
    "                                               engine='fiona')\n",
    "        \n",
    "        self.weather_dtm = self.weather_dtm.values\n",
    "        self.weather_dtm = np.moveaxis(self.weather_dtm, 0,-1)\n",
    "\n",
    "    def loading_point_wtd(self, fill_value = 0):\n",
    "        \n",
    "        # Water Table Depth data loading\n",
    "        self.wtd_df = pd.read_csv(self.dict_files[\"wtd_csv_path\"], \n",
    "                                    dtype= {\"sensor_id\": \"str\"})\n",
    "        self.wtd_df = self.wtd_df.astype({\"date\":'datetime64[ns]'})\n",
    "\n",
    "        # Water Table Depth Sensors shapefile loading: \n",
    "        self.wtd_names = gpd.read_file(self.dict_files[\"wtd_shp\"],\n",
    "                                             engine='fiona')\n",
    "        self.wtd_names = self.wtd_names.to_crs('epsg:4326')\n",
    "\n",
    "        # Define attributes about dates and coordinates\n",
    "        self.dates = self.wtd_df[\"date\"].unique()\n",
    "        self.sensor_id_list = self.wtd_df[\"sensor_id\"].unique()\n",
    "        \n",
    "        \n",
    "        ### Merge csv and shp into a joint spatio temporal representation\n",
    "        sensor_coord_x_list = []\n",
    "        sensor_coord_y_list = []\n",
    "\n",
    "        # Retrieve coordinates from id codes\n",
    "        for sensor in self.sensor_id_list:\n",
    "            coord_x = self.wtd_names.loc[self.wtd_names[\"sensor_id\"] == sensor].geometry.x.values[0]\n",
    "            coord_y = self.wtd_names.loc[self.wtd_names[\"sensor_id\"] == sensor].geometry.y.values[0]\n",
    "            sensor_coord_x_list.append(coord_x)\n",
    "            sensor_coord_y_list.append(coord_y)\n",
    "\n",
    "        # Buil a dictionary of coordinates and id codes\n",
    "        from_id_to_coord_x_dict = {self.sensor_id_list[i]: sensor_coord_x_list[i] for i in range(len(sensor_coord_x_list))}\n",
    "        from_id_to_coord_y_dict = {self.sensor_id_list[i]: sensor_coord_y_list[i] for i in range(len(sensor_coord_y_list))}\n",
    "\n",
    "        # Map id codes to coordinates for all rows in the original ds\n",
    "        queries = list(self.wtd_df[\"sensor_id\"].values)\n",
    "        coordinates_x = itemgetter(*queries)(from_id_to_coord_x_dict)\n",
    "        coordinates_y = itemgetter(*queries)(from_id_to_coord_y_dict)\n",
    "\n",
    "        # insert new columns containing coordinates\n",
    "        self.wtd_df[\"x\"] = coordinates_x\n",
    "        self.wtd_df[\"y\"] = coordinates_y\n",
    "        \n",
    "        self.wtd_df = self.wtd_df.set_index([\"date\",\"y\",\"x\"])\n",
    "        \n",
    "        # Subset wtd data truncating the last `timestep` instances\n",
    "        last_date = self.dates.max() - np.timedelta64(self.timesteps, 'D')\n",
    "        self.input_dates = self.dates[self.dates <= last_date]\n",
    "        \n",
    "        # Create nan-mask\n",
    "        self.wtd_df[\"nan_mask\"] = ~self.wtd_df[\"wtd\"].isna()\n",
    "        #self.wtd_df[\"wtd\"] = self.wtd_df[\"wtd\"].fillna(fill_value)\n",
    "        \n",
    "    def __len__(self):\n",
    "        data = self.wtd_df.loc[pd.IndexSlice[self.wtd_df.index.get_level_values(0) <= self.input_dates.max(),\n",
    "                                                       :,\n",
    "                                                       :]]\n",
    "        return len(data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if idx < 0:\n",
    "            idx = self.__len__() + idx\n",
    "        \n",
    "        # Retrieve date and coords for idx instance\n",
    "        start_date = self.wtd_df.iloc[idx, :].dropna().name[0]\n",
    "        sample_lat = self.wtd_df.iloc[idx, :].dropna().name[1]\n",
    "        sample_lon = self.wtd_df.iloc[idx, :].dropna().name[2]\n",
    "        sample_dtm = self.dtm_roi.sel(x = sample_lon,\n",
    "                                      y = sample_lat,\n",
    "                                      method = \"nearest\").values  \n",
    "        \n",
    "        end_date = start_date + np.timedelta64(self.timesteps, \"D\")\n",
    "        \n",
    "        # print(\"start date: \", str(start_date))\n",
    "        # print(\"end date: \", str(end_date))\n",
    "        \n",
    "        # Initial state WTD (t0) data\n",
    "        wtd_t0 = self.wtd_df[[\"wtd\", \"nan_mask\"]].loc[self.wtd_df.index.get_level_values(0) == start_date]\n",
    "        wtd_t0_values = wtd_t0[\"wtd\"].values\n",
    "        wtd_t0_mask = wtd_t0[\"nan_mask\"].values\n",
    "        wtd_t0_lat = wtd_t0.index.get_level_values(1).values\n",
    "        wtd_t0_lon = wtd_t0.index.get_level_values(2).values\n",
    "        wtd_t0_dtm = np.array([self.dtm_roi.sel(x = wtd_t0_lon[sensor],\n",
    "                                                y = wtd_t0_lat[sensor],\n",
    "                                                method = \"nearest\") for sensor in range(len(wtd_t0_lat))]).squeeze()\n",
    "        \n",
    "        #wtd_t0_mask = 1*~np.isnan(wtd_t0_values)\n",
    "        X = [torch.from_numpy(wtd_t0_lat).to(torch.float32),\n",
    "             torch.from_numpy(wtd_t0_lon).to(torch.float32),\n",
    "             torch.from_numpy(wtd_t0_dtm).to(torch.float32),\n",
    "             torch.from_numpy(wtd_t0_values).to(torch.float32)\n",
    "             ]\n",
    "        X = torch.stack(X, dim = -1)\n",
    "        \n",
    "        Z = [torch.tensor(sample_lat).reshape(1).to(torch.float32),\n",
    "             torch.tensor(sample_lon).reshape(1).to(torch.float32),\n",
    "             torch.tensor(sample_dtm).reshape(1).to(torch.float32)]\n",
    "        \n",
    "        Z = torch.stack(Z, dim = -1).squeeze()\n",
    "        \n",
    "        # Retrieve weather data\n",
    "        weather_video = self.weather_xr.sel(time = slice(start_date + np.timedelta64(1, \"D\"),\n",
    "                                                    end_date)) #slice include extremes\n",
    "        weather_video = weather_video.to_array().values\n",
    "        W = torch.from_numpy(weather_video).to(torch.float32)\n",
    "        \n",
    "        # Retrieve wtd values from t0+1 to T for the idx instance sensor\n",
    "        wtd_t1_T = self.wtd_df[[\"wtd\", \"nan_mask\"]].loc[(self.wtd_df.index.get_level_values(0) > start_date) &\n",
    "                                          (self.wtd_df.index.get_level_values(0) <= end_date)  & \n",
    "                                          (self.wtd_df.index.get_level_values(1) == sample_lat)&\n",
    "                                          (self.wtd_df.index.get_level_values(2) == sample_lon)]\n",
    "        \n",
    "        wtd_t1_T_values =  wtd_t1_T[\"wtd\"].values\n",
    "        wtd_t1_T_mask =  wtd_t1_T[\"nan_mask\"].values        \n",
    "        \n",
    "        Y = torch.from_numpy(wtd_t1_T_values).to(torch.float32)\n",
    "        \n",
    "        X_mask = torch.from_numpy(wtd_t0_mask).to(torch.bool)\n",
    "                 \n",
    "        Y_mask = torch.from_numpy(wtd_t1_T_mask).to(torch.bool)\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return [X, Z, W, Y, X_mask, Y_mask]\n",
    "    \n",
    "    def get_weather_dtm(self):\n",
    "        return torch.from_numpy(self.weather_dtm).to(torch.float32)\n",
    "        \n",
    "    def get_weather_coords(self):\n",
    "        return torch.from_numpy(self.weather_coords).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ContinuousDataset(dict_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the dataset: 254820\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of the dataset: {ds.__len__()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "class Continuous1DNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 timestep = 180,\n",
    "                 cb_fc_layer = 5,\n",
    "                 cb_fc_neurons = 32,\n",
    "                 conv_filters = 32,\n",
    "                 lstm_layer = 5,\n",
    "                 lstm_input_units = 16,\n",
    "                 lstm_units = 32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.timestep = timestep\n",
    "        self.lstm_layer = lstm_layer\n",
    "        self.lstm_input_units = lstm_input_units\n",
    "        self.lstm_units = lstm_units\n",
    "        self.cb_fc_layer = cb_fc_layer\n",
    "        self.cb_fc_neurons = cb_fc_neurons\n",
    "        self.conv_filters = conv_filters\n",
    "        \n",
    "        self.wgamma = nn.Sigmoid()\n",
    "        # Fully connected\n",
    "        cb_fc = []\n",
    "        cb_fc.append(nn.Linear(4, self.cb_fc_neurons))\n",
    "        cb_fc.append(nn.ReLU())\n",
    "        for l in range(self.cb_fc_layer - 2):\n",
    "            cb_fc.append(nn.Linear(self.cb_fc_neurons, self.cb_fc_neurons))\n",
    "            cb_fc.append(nn.ReLU())\n",
    "        \n",
    "        cb_fc.append(nn.Linear(self.cb_fc_neurons, self.lstm_units))\n",
    "        cb_fc.append(nn.ReLU())\n",
    "        self.cb_fc = nn.Sequential(*cb_fc)\n",
    "        \n",
    "        # Weather block\n",
    "        self.weather_wgamma = nn.Sigmoid()\n",
    "        \n",
    "        conv3d_stack=[]\n",
    "        conv3d_stack.append(nn.Conv3d(10, self.conv_filters, (1,2,2))) # Conv input (N, C, D, H, W) - kernel 3d (D, H, W)\n",
    "        conv3d_stack.append(nn.BatchNorm3d(self.conv_filters))\n",
    "        conv3d_stack.append(nn.ReLU())\n",
    "        \n",
    "        for i in range(4):\n",
    "            conv3d_stack.append(nn.Conv3d(self.conv_filters, self.conv_filters, (1,2,2)))\n",
    "            conv3d_stack.append(nn.BatchNorm3d(self.conv_filters))\n",
    "            conv3d_stack.append(nn.ReLU())\n",
    "            \n",
    "        conv3d_stack.append(nn.AdaptiveAvgPool3d((None,4,4)))\n",
    "        conv3d_stack.append(nn.Conv3d(self.conv_filters, self.conv_filters, (1,2,2)))\n",
    "        conv3d_stack.append(nn.BatchNorm3d(self.conv_filters))\n",
    "        conv3d_stack.append(nn.ReLU())\n",
    "        conv3d_stack.append(nn.Conv3d(self.conv_filters, self.conv_filters, (1,2,2)))\n",
    "        conv3d_stack.append(nn.BatchNorm3d(self.conv_filters))\n",
    "        conv3d_stack.append(nn.ReLU())\n",
    "        conv3d_stack.append(nn.Conv3d(self.conv_filters, self.lstm_input_units, (1,2,2)))\n",
    "        conv3d_stack.append(nn.BatchNorm3d(self.lstm_input_units))\n",
    "        conv3d_stack.append(nn.ReLU())\n",
    "        self.conv3d_stack = nn.Sequential(*conv3d_stack)\n",
    "            \n",
    "        # Joint sequental block\n",
    "        self.lstm_1 = nn.LSTM(self.lstm_input_units, self.lstm_units,\n",
    "                              batch_first=True,\n",
    "                              num_layers=self.lstm_layer) # Batch first input (N,L,H)\n",
    "        \n",
    "        fc = []\n",
    "        fc.append(nn.Linear(self.lstm_units, 8))\n",
    "        fc.append(nn.ReLU())\n",
    "        fc.append(nn.Linear(8, 1))\n",
    "        self.fc = nn.Sequential(*fc)\n",
    "\n",
    "\n",
    "    def forward(self, x, z, w, x_mask):\n",
    "        \"\"\"\n",
    "        input : x (31, 5); z (1, 3); w[0] (10, 180, 9, 12); w[1] (9, 12, 3)\n",
    "        return \n",
    "            lstm_out (array): lstm_out = [S_we, M, P_r, Es, K_s, K_r]\n",
    "        x: tensor of shape (L,Hin) if minibatches itaration (L,N,Hin) when batch_first=False (default)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Conditioning block\n",
    "        \n",
    "        wtd_sim = torch.matmul(x[:,:,:3], z.unsqueeze(-1))\n",
    "        wtd_sim = self.wgamma(wtd_sim)\n",
    "        wtd_sim = wtd_sim.squeeze() * x_mask # masking nan\n",
    "        wtd0 = torch.sum(x[:,:,-2] * wtd_sim, dim = 1)/torch.sum(wtd_sim, dim = 1)\n",
    "        wtd0 = torch.cat([z, wtd0.unsqueeze(-1)], dim = -1)\n",
    "        \n",
    "        wtd0 = self.cb_fc(wtd0)\n",
    "        \n",
    "        # Weather block\n",
    "        ## w[0] (10, 180, 9, 12); w[1] (9, 12, 3)\n",
    "        weather_sim = w[1] * z[:,None,None,:].expand(-1, w[1].shape[1], w[1].shape[2], -1)\n",
    "        weather_sim = torch.sum(weather_sim, dim = -1)\n",
    "        weather_sim = self.weather_wgamma(weather_sim)\n",
    "        weather_sim = weather_sim[:, None, None, : ,:].expand(-1, w[0].shape[1], w[0].shape[2], -1, -1 )\n",
    "        \n",
    "        weather = w[0] * weather_sim\n",
    "        \n",
    "        wb_td3dconv = self.conv3d_stack(weather)\n",
    "        \n",
    "        wb_td3dconv = wb_td3dconv.squeeze()\n",
    "        wb_td3dconv = torch.moveaxis(wb_td3dconv, 1, -1)\n",
    "        \n",
    "        # Sequential block\n",
    "        wtd0 = wtd0.unsqueeze(1).expand([-1,self.lstm_layer,-1])\n",
    "        wtd0 = torch.movedim(wtd0, 0, 1)\n",
    "        \n",
    "        wtd_series = self.lstm_1(wb_td3dconv,\n",
    "                                 (wtd0.contiguous(),\n",
    "                                  wtd0.contiguous())) #input  [input, (h_0, c_0)] - h and c (D∗num_layers,N,H)\n",
    "        \n",
    "        wtd_series = self.fc(wtd_series[0])\n",
    "        \n",
    "        return wtd_series.squeeze()\n",
    "\n",
    "model = Continuous1DNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parameters:  33201\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of trainable parameters: \" ,sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing size: 8000, Test size: 2000\n"
     ]
    }
   ],
   "source": [
    "batch_size = dict_files[\"batch_size\"]\n",
    "max_epochs = dict_files[\"epochs\"]\n",
    "\n",
    "test_split_p = dict_files[\"test_split_p\"]\n",
    "train_split_p = 1 - test_split_p\n",
    "\n",
    "max_ds_elems = ds.__len__()\n",
    "if not dict_files[\"all_dataset\"]:\n",
    "    max_ds_elems = dict_files[\"max_ds_elems\"]\n",
    "\n",
    "train_idx = int(max_ds_elems*train_split_p)\n",
    "test_idx = int(max_ds_elems*test_split_p)\n",
    "\n",
    "print(f\"Traing size: {train_idx}, Test size: {test_idx}\")\n",
    "\n",
    "train_idxs, test_idxs = np.arange(train_idx), np.arange(train_idx, train_idx + test_idx)\n",
    "\n",
    "train_sampler = SequentialSampler(train_idxs)\n",
    "test_sampler = SequentialSampler(test_idxs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=ds,\n",
    "                                            batch_size=batch_size,\n",
    "                                            sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=ds,\n",
    "                                            batch_size=batch_size,\n",
    "                                            sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(x, y, y_hat, save_dir = None, title = None):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.suptitle(\"Loss vs iterations\")\n",
    "    ax.plot(x, y_hat, label = \"predicted\")\n",
    "    ax.plot(x, y, label = \"true\")\n",
    "    ax.legend()\n",
    "    \n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "        \n",
    "    if save_dir:\n",
    "        plt.savefig(f\"{save_dir}.png\", bbox_inches = 'tight') #dpi = 400, transparent = True\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse(y_hat, y, mask):\n",
    "    # y_hat = y_hat.to(device)\n",
    "    # y = y.to(device)\n",
    "    # mask = mask.to(device)\n",
    "    return torch.sum(((y_hat[mask]-y[mask]))**2.0)  / torch.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    entity=\"gsartor-unito\",\n",
    "    project=dict_files[\"experiment_name\"],\n",
    "    dir =dict_files[\"wandb_dir\"],\n",
    "    config=dict_files,\n",
    "    mode=\"offline\",\n",
    ")\n",
    "\n",
    "# Magic\n",
    "wandb.watch(model, log_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem allocated in MB:  0.0\n",
      "############### Training epoch 0 ###############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/32 [00:11<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim torch.Size([256, 31, 1])\n",
      "gammawtd0 torch.Size([256, 31])\n",
      "torch.Size([256, 31])\n",
      "wtd0 torch.Size([256])\n",
      "wtd0 torch.Size([256, 4])\n",
      "wtd0 torch.Size([256, 32])\n",
      "weather_sim torch.Size([256, 9, 12, 3])\n",
      "weather_sim torch.Size([256, 9, 12])\n",
      "weather_sim_gamma torch.Size([256, 9, 12])\n",
      "weather torch.Size([256, 10, 180, 9, 12])\n",
      "ts torch.Size([256, 16, 180, 1, 1])\n",
      "ts-ma torch.Size([256, 180, 16])\n",
      "wtd_series torch.Size([256, 180, 32])\n",
      "Train loss: 443.6900939941406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   3%|▎         | 1/32 [00:30<09:49, 19.03s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim torch.Size([256, 31, 1])\n",
      "gammawtd0 torch.Size([256, 31])\n",
      "torch.Size([256, 31])\n",
      "wtd0 torch.Size([256])\n",
      "wtd0 torch.Size([256, 4])\n",
      "wtd0 torch.Size([256, 32])\n",
      "weather_sim torch.Size([256, 9, 12, 3])\n",
      "weather_sim torch.Size([256, 9, 12])\n",
      "weather_sim_gamma torch.Size([256, 9, 12])\n",
      "weather torch.Size([256, 10, 180, 9, 12])\n",
      "ts torch.Size([256, 16, 180, 1, 1])\n",
      "ts-ma torch.Size([256, 180, 16])\n",
      "wtd_series torch.Size([256, 180, 32])\n",
      "Train loss: 462.2015380859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   6%|▋         | 2/32 [00:43<10:51, 21.71s/batch]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m############### Training epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ###############\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(train_loader, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m tepoch:\n\u001b[0;32m---> 19\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtepoch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtepoch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_description\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEpoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/leonardo_work/IscrC_DL4EO/my_venv/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m/leonardo_work/IscrC_DL4EO/my_venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m/leonardo_work/IscrC_DL4EO/my_venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/leonardo_work/IscrC_DL4EO/my_venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/leonardo_work/IscrC_DL4EO/my_venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[4], line 133\u001b[0m, in \u001b[0;36mContinuousDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    131\u001b[0m wtd_t0_lat \u001b[38;5;241m=\u001b[39m wtd_t0\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_level_values(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m    132\u001b[0m wtd_t0_lon \u001b[38;5;241m=\u001b[39m wtd_t0\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_level_values(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 133\u001b[0m wtd_t0_dtm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtm_roi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwtd_t0_lon\u001b[49m\u001b[43m[\u001b[49m\u001b[43msensor\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwtd_t0_lat\u001b[49m\u001b[43m[\u001b[49m\u001b[43msensor\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnearest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwtd_t0_lat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m#wtd_t0_mask = 1*~np.isnan(wtd_t0_values)\u001b[39;00m\n\u001b[1;32m    138\u001b[0m X \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mfrom_numpy(wtd_t0_lat)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m    139\u001b[0m      torch\u001b[38;5;241m.\u001b[39mfrom_numpy(wtd_t0_lon)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m    140\u001b[0m      torch\u001b[38;5;241m.\u001b[39mfrom_numpy(wtd_t0_dtm)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m    141\u001b[0m      torch\u001b[38;5;241m.\u001b[39mfrom_numpy(wtd_t0_values)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    142\u001b[0m      ]\n",
      "Cell \u001b[0;32mIn[4], line 133\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    131\u001b[0m wtd_t0_lat \u001b[38;5;241m=\u001b[39m wtd_t0\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_level_values(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m    132\u001b[0m wtd_t0_lon \u001b[38;5;241m=\u001b[39m wtd_t0\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_level_values(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 133\u001b[0m wtd_t0_dtm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtm_roi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwtd_t0_lon\u001b[49m\u001b[43m[\u001b[49m\u001b[43msensor\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwtd_t0_lat\u001b[49m\u001b[43m[\u001b[49m\u001b[43msensor\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnearest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m sensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(wtd_t0_lat))])\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m#wtd_t0_mask = 1*~np.isnan(wtd_t0_values)\u001b[39;00m\n\u001b[1;32m    138\u001b[0m X \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mfrom_numpy(wtd_t0_lat)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m    139\u001b[0m      torch\u001b[38;5;241m.\u001b[39mfrom_numpy(wtd_t0_lon)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m    140\u001b[0m      torch\u001b[38;5;241m.\u001b[39mfrom_numpy(wtd_t0_dtm)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m    141\u001b[0m      torch\u001b[38;5;241m.\u001b[39mfrom_numpy(wtd_t0_values)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    142\u001b[0m      ]\n",
      "File \u001b[0;32m/leonardo_work/IscrC_DL4EO/my_venv/lib/python3.11/site-packages/xarray/core/dataarray.py:1675\u001b[0m, in \u001b[0;36mDataArray.sel\u001b[0;34m(self, indexers, method, tolerance, drop, **indexers_kwargs)\u001b[0m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msel\u001b[39m(\n\u001b[1;32m   1560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1561\u001b[0m     indexers: Mapping[Any, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mindexers_kwargs: Any,\n\u001b[1;32m   1566\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1567\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a new DataArray whose data is given by selecting index\u001b[39;00m\n\u001b[1;32m   1568\u001b[0m \u001b[38;5;124;03m    labels along the specified dimension(s).\u001b[39;00m\n\u001b[1;32m   1569\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;124;03m    Dimensions without coordinates: points\u001b[39;00m\n\u001b[1;32m   1674\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1675\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_temp_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindexers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1680\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mindexers_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1681\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1682\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_temp_dataset(ds)\n",
      "File \u001b[0;32m/leonardo_work/IscrC_DL4EO/my_venv/lib/python3.11/site-packages/xarray/core/dataset.py:3223\u001b[0m, in \u001b[0;36mDataset.sel\u001b[0;34m(self, indexers, method, tolerance, drop, **indexers_kwargs)\u001b[0m\n\u001b[1;32m   3155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a new dataset with each array indexed by tick labels\u001b[39;00m\n\u001b[1;32m   3156\u001b[0m \u001b[38;5;124;03malong the specified dimension(s).\u001b[39;00m\n\u001b[1;32m   3157\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3220\u001b[0m \n\u001b[1;32m   3221\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3222\u001b[0m indexers \u001b[38;5;241m=\u001b[39m either_dict_or_kwargs(indexers, indexers_kwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 3223\u001b[0m query_results \u001b[38;5;241m=\u001b[39m \u001b[43mmap_index_queries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3224\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\n\u001b[1;32m   3225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m drop:\n\u001b[1;32m   3228\u001b[0m     no_scalar_variables \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/leonardo_work/IscrC_DL4EO/my_venv/lib/python3.11/site-packages/xarray/core/indexing.py:194\u001b[0m, in \u001b[0;36mmap_index_queries\u001b[0;34m(obj, indexers, method, tolerance, **indexers_kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(IndexSelResult(labels))\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 194\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    196\u001b[0m merged \u001b[38;5;241m=\u001b[39m merge_sel_results(results)\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# drop dimension coordinates found in dimension indexers\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# (also drop multi-index if any)\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m# (.sel() already ensures alignment)\u001b[39;00m\n",
      "File \u001b[0;32m/leonardo_work/IscrC_DL4EO/my_venv/lib/python3.11/site-packages/xarray/core/indexes.py:780\u001b[0m, in \u001b[0;36mPandasIndex.sel\u001b[0;34m(self, labels, method, tolerance)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 780\u001b[0m         indexer \u001b[38;5;241m=\u001b[39m \u001b[43mget_indexer_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(indexer \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    784\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m    785\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot all values found in index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcoord_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    786\u001b[0m             )\n",
      "File \u001b[0;32m/leonardo_work/IscrC_DL4EO/my_venv/lib/python3.11/site-packages/xarray/core/indexes.py:561\u001b[0m, in \u001b[0;36mget_indexer_nd\u001b[0;34m(index, labels, method, tolerance)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flat_labels\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat16\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    560\u001b[0m     flat_labels \u001b[38;5;241m=\u001b[39m flat_labels\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 561\u001b[0m flat_indexer \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m indexer \u001b[38;5;241m=\u001b[39m flat_indexer\u001b[38;5;241m.\u001b[39mreshape(labels\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indexer\n",
      "File \u001b[0;32m/leonardo_work/IscrC_DL4EO/my_venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3880\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3878\u001b[0m method \u001b[38;5;241m=\u001b[39m clean_reindex_fill_method(method)\n\u001b[1;32m   3879\u001b[0m orig_target \u001b[38;5;241m=\u001b[39m target\n\u001b[0;32m-> 3880\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_cast_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3882\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[1;32m   3884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n",
      "File \u001b[0;32m/leonardo_work/IscrC_DL4EO/my_venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:6679\u001b[0m, in \u001b[0;36mIndex._maybe_cast_listlike_indexer\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m   6673\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6674\u001b[0m \u001b[38;5;124;03m    If we have a float key and are not a floating index, then try to cast\u001b[39;00m\n\u001b[1;32m   6675\u001b[0m \u001b[38;5;124;03m    to an int if equivalent.\u001b[39;00m\n\u001b[1;32m   6676\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   6677\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m key\n\u001b[0;32m-> 6679\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_cast_listlike_indexer\u001b[39m(\u001b[38;5;28mself\u001b[39m, target) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[1;32m   6680\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6681\u001b[0m \u001b[38;5;124;03m    Analogue to maybe_cast_indexer for get_indexer instead of get_loc.\u001b[39;00m\n\u001b[1;32m   6682\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   6683\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ensure_index(target)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "weather_coords = ds.get_weather_coords()\n",
    "weather_dtm = ds.get_weather_dtm()\n",
    "weather_coords = torch.cat([weather_coords, weather_dtm], dim = -1)\n",
    "\n",
    "print('mem allocated in MB: ', torch.cuda.memory_allocated() / 1024**2)\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "\n",
    "for i in range(max_epochs):\n",
    "    \n",
    "    model.train(True)\n",
    "    start_time = time.time()\n",
    "    print(f\"############### Training epoch {i} ###############\")\n",
    "    \n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "            for batch_idx, (x, z, w_values, y, x_mask, y_mask) in enumerate(tepoch):\n",
    "                tepoch.set_description(f\"Epoch {i}\")\n",
    "                \n",
    "                x = x.to(device)\n",
    "                x_mask = x_mask.to(device)\n",
    "                z = z.to(device)\n",
    "                weather_coords_batch = weather_coords.unsqueeze(0).expand(w_values.shape[0], -1, -1, -1)\n",
    "                w = [w_values.to(device), weather_coords_batch.to(device)]\n",
    "                y = y.to(device)\n",
    "                y_mask = y_mask.to(device)\n",
    "                #print('Batch mem allocated in MB: ', torch.cuda.memory_allocated() / 1024**2)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                y_hat = model(x, z, w, x_mask)\n",
    "                #print('After predict mem allocated in MB: ', torch.cuda.memory_allocated() / 1024**2)\n",
    "                loss = masked_mse(y_hat,\n",
    "                                  y,\n",
    "                                  y_mask)\n",
    "                \n",
    "                print(f\"Train loss: {loss}\")\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                metrics = {\n",
    "                    \"train_loss\" : loss\n",
    "                }\n",
    "                wandb.log(metrics)              \n",
    "                \n",
    "    end_time = time.time()\n",
    "    exec_time = end_time-start_time\n",
    "\n",
    "    wandb.log({\"tr_epoch_exec_t\" : exec_time})\n",
    "    # Log the plot\n",
    "    wandb.log({\"training_pred\": plot_predictions(np.arange(0,len(y_hat)), y[-1,:,0], y_hat,\n",
    "                                        title = f\"lat: {z[-1,0]} lon:{z[-1,1]} dtm{z[-1,2]}\")})\n",
    "\n",
    "    model_name = 'model_{}_{}.pt'.format(timestamp, i)    \n",
    "    model_dir = dict_files[\"save_model_dir\"]\n",
    "    torch.save(model.state_dict(), f\"{model_dir}/{model_name}\") \n",
    "\n",
    "    print(f\"############### Test epoch {i} ###############\")\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
    "                for batch_idx, (x, z, w_values, y, x_mask, y_mask) in enumerate(tepoch):\n",
    "                    tepoch.set_description(f\"Epoch {i}\")\n",
    "\n",
    "                    x = x.to(device)\n",
    "                    x_mask = x_mask.to(device)\n",
    "                    z = z.to(device)\n",
    "                    weather_coords_batch = weather_coords.unsqueeze(0).expand(w_values.shape[0], -1, -1, -1)\n",
    "                    w = [w_values.to(device), weather_coords_batch.to(device)]\n",
    "                    y = y.to(device)\n",
    "                    y_mask = y_mask.to(device)\n",
    "                    # print('Batch mem allocated in MB: ', torch.cuda.memory_allocated() / 1024**2)\n",
    "\n",
    "                    y_hat = model(x, z, w, x_mask)\n",
    "                    # print('After predict mem allocated in MB: ', torch.cuda.memory_allocated() / 1024**2)\n",
    "\n",
    "                    loss = masked_mse(y_hat,\n",
    "                                  y,\n",
    "                                  y_mask)\n",
    "                    print(f\"Test loss: {loss}\")\n",
    "\n",
    "                    metrics = {\n",
    "                        \"test_loss\" : loss\n",
    "                    }\n",
    "\n",
    "                    wandb.log(metrics)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    exec_time = end_time-start_time\n",
    "    wandb.log({\"test_epoch_exec_t\" : exec_time})\n",
    "    # Log the plot\n",
    "    wandb.log({\"test_pred\": plot_predictions(np.arange(0,len(y_hat)), y[-1,:,0], y_hat,\n",
    "                                        title = f\"lat: {z[-1,0]} lon:{z[-1,1]} dtm{z[-1,2]}\")})\n",
    "\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "print(f\"Execution time: {end_time-start_time}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
