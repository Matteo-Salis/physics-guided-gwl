{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray\n",
    "import rioxarray\n",
    "import fiona\n",
    "\n",
    "#import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from rasterio.enums import Resampling\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = \"/leonardo_scratch/fast/IscrC_DL4EO/github/water-pinns/src/configs/discrete_2D_wtd/test_1D.json\"\n",
    "dict_files = {}\n",
    "with open(json_file) as f:\n",
    "    dict_files = json.load(f)\n",
    "    print(f\"Read data.json: {dict_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ContinuousDataset(Dataset):\n",
    "    \"\"\"Weather and WTD Dataset for the continuous case model\"\"\"\n",
    "\n",
    "    def __init__(self, dict_files, #meteo_nc_path, wtd_csv_path, wtd_stations_shp_path,\n",
    "                 fill_value = 0,\n",
    "                 transform = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dict_files (string): Path to the .nc file.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                    on a sample.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Attributes init\n",
    "        self.dict_files = dict_files\n",
    "        self.timesteps = self.dict_files[\"timesteps\"]\n",
    "\n",
    "        # Meteorological data loading \n",
    "        self.loading_weather()\n",
    "        \n",
    "        # Digital Terrain Model data loading\n",
    "        self.loading_dtm()\n",
    "        \n",
    "        # Water Table Depth data loading \n",
    "        self.loading_point_wtd(fill_value = fill_value)\n",
    "\n",
    "        # Transform       \n",
    "        self.transform = transform\n",
    "        \n",
    "    def loading_dtm(self):\n",
    "        self.dtm_roi = rioxarray.open_rasterio(self.dict_files[\"dtm_nc\"],\n",
    "                                               engine='fiona')\n",
    "        self.dtm_roi = self.dtm_roi.rio.write_crs(\"epsg:4326\")\n",
    "        \n",
    "            \n",
    "    def loading_weather(self):\n",
    "        self.weather_xr = xarray.open_dataset(self.dict_files[\"weather_nc_path\"])\n",
    "        self.weather_xr = self.weather_xr.rio.write_crs(\"epsg:4326\")\n",
    "        \n",
    "        # Compute coord matrix\n",
    "        lat_matrix = np.vstack([self.weather_xr.lat.values for i in range(len(self.weather_xr.lon.values))]).transpose()\n",
    "        lon_matrix = np.vstack([self.weather_xr.lon.values for i in range(len(self.weather_xr.lat.values))])\n",
    "        \n",
    "        self.weather_coords = np.stack([lat_matrix,lon_matrix], axis = -1)\n",
    "        \n",
    "        self.weather_dtm = rioxarray.open_rasterio(self.dict_files[\"weather_dtm\"],\n",
    "                                               engine='fiona')\n",
    "        \n",
    "        self.weather_dtm = self.weather_dtm.values\n",
    "        self.weather_dtm = np.moveaxis(self.weather_dtm, 0,-1)\n",
    "\n",
    "    def loading_point_wtd(self, fill_value = 0):\n",
    "        \n",
    "        # Water Table Depth data loading\n",
    "        self.wtd_df = pd.read_csv(self.dict_files[\"wtd_csv_path\"], \n",
    "                                    dtype= {\"sensor_id\": \"str\"})\n",
    "        self.wtd_df = self.wtd_df.astype({\"date\":'datetime64[ns]'})\n",
    "\n",
    "        # Water Table Depth Sensors shapefile loading: \n",
    "        self.wtd_names = gpd.read_file(self.dict_files[\"wtd_shp\"],\n",
    "                                             engine='fiona')\n",
    "        self.wtd_names = self.wtd_names.to_crs('epsg:4326')\n",
    "\n",
    "        # Define attributes about dates and coordinates\n",
    "        self.dates = self.wtd_df[\"date\"].unique()\n",
    "        self.sensor_id_list = self.wtd_df[\"sensor_id\"].unique()\n",
    "        \n",
    "        \n",
    "        ### Merge csv and shp into a joint spatio temporal representation\n",
    "        sensor_coord_x_list = []\n",
    "        sensor_coord_y_list = []\n",
    "\n",
    "        # Retrieve coordinates from id codes\n",
    "        for sensor in self.sensor_id_list:\n",
    "            coord_x = self.wtd_names.loc[self.wtd_names[\"sensor_id\"] == sensor].geometry.x.values[0]\n",
    "            coord_y = self.wtd_names.loc[self.wtd_names[\"sensor_id\"] == sensor].geometry.y.values[0]\n",
    "            sensor_coord_x_list.append(coord_x)\n",
    "            sensor_coord_y_list.append(coord_y)\n",
    "\n",
    "        # Buil a dictionary of coordinates and id codes\n",
    "        from_id_to_coord_x_dict = {self.sensor_id_list[i]: sensor_coord_x_list[i] for i in range(len(sensor_coord_x_list))}\n",
    "        from_id_to_coord_y_dict = {self.sensor_id_list[i]: sensor_coord_y_list[i] for i in range(len(sensor_coord_y_list))}\n",
    "\n",
    "        # Map id codes to coordinates for all rows in the original ds\n",
    "        queries = list(self.wtd_df[\"sensor_id\"].values)\n",
    "        coordinates_x = itemgetter(*queries)(from_id_to_coord_x_dict)\n",
    "        coordinates_y = itemgetter(*queries)(from_id_to_coord_y_dict)\n",
    "\n",
    "        # insert new columns containing coordinates\n",
    "        self.wtd_df[\"x\"] = coordinates_x\n",
    "        self.wtd_df[\"y\"] = coordinates_y\n",
    "        \n",
    "        self.wtd_df = self.wtd_df.set_index([\"date\",\"y\",\"x\"])\n",
    "        \n",
    "        # Subset wtd data truncating the last `timestep` instances\n",
    "        last_date = self.dates.max() - np.timedelta64(self.timesteps, 'D')\n",
    "        self.input_dates = self.dates[self.dates <= last_date]\n",
    "        \n",
    "        # Create nan-mask\n",
    "        self.wtd_df[\"nan_mask\"] = 1*~self.wtd_df[\"wtd\"].isna()\n",
    "        self.wtd_df[\"wtd\"] = self.wtd_df[\"wtd\"].fillna(fill_value)\n",
    "        \n",
    "    def __len__(self):\n",
    "        data = self.wtd_df.loc[pd.IndexSlice[self.wtd_df.index.get_level_values(0) <= self.input_dates.max(),\n",
    "                                                       :,\n",
    "                                                       :]]\n",
    "        return len(data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if idx < 0:\n",
    "            idx = self.__len__() + idx\n",
    "        \n",
    "        # Retrieve date and coords for idx instance\n",
    "        start_date = self.wtd_df.iloc[idx, :].name[0]\n",
    "        sample_lat = self.wtd_df.iloc[idx, :].name[1]\n",
    "        sample_lon = self.wtd_df.iloc[idx, :].name[2]\n",
    "        sample_dtm = self.dtm_roi.sel(x = sample_lon,\n",
    "                                      y = sample_lat,\n",
    "                                      method = \"nearest\").values  \n",
    "        \n",
    "        end_date = start_date + np.timedelta64(self.timesteps, \"D\")\n",
    "        \n",
    "        # print(\"start date: \", str(start_date))\n",
    "        # print(\"end date: \", str(end_date))\n",
    "        \n",
    "        # Initial state WTD (t0) data\n",
    "        wtd_t0 = self.wtd_df[[\"wtd\", \"nan_mask\"]].loc[self.wtd_df.index.get_level_values(0) == start_date]\n",
    "        wtd_t0_values = wtd_t0[\"wtd\"].values\n",
    "        #wtd_t0_mask = wtd_t0[\"nan_mask\"].values\n",
    "        wtd_t0_lat = wtd_t0.index.get_level_values(1).values\n",
    "        wtd_t0_lon = wtd_t0.index.get_level_values(2).values\n",
    "        wtd_t0_dtm = np.array([self.dtm_roi.sel(x = wtd_t0_lon[sensor],\n",
    "                                                y = wtd_t0_lat[sensor],\n",
    "                                                method = \"nearest\") for sensor in range(len(wtd_t0_lat))]).squeeze()\n",
    "        \n",
    "        #wtd_t0_mask = 1*~np.isnan(wtd_t0_values)\n",
    "        X = [torch.from_numpy(wtd_t0_lat).to(torch.float32),\n",
    "             torch.from_numpy(wtd_t0_lon).to(torch.float32),\n",
    "             torch.from_numpy(wtd_t0_dtm).to(torch.float32),\n",
    "             torch.from_numpy(wtd_t0_values).to(torch.float32),\n",
    "             #torch.from_numpy(wtd_t0_mask).to(torch.float32)\n",
    "             ]\n",
    "        X = torch.stack(X, dim = -1)\n",
    "        \n",
    "        Z = [torch.tensor(sample_lat).reshape(1).to(torch.float32),\n",
    "             torch.tensor(sample_lon).reshape(1).to(torch.float32),\n",
    "             torch.tensor(sample_dtm).reshape(1).to(torch.float32)]\n",
    "        \n",
    "        Z = torch.stack(Z, dim = -1).squeeze()\n",
    "        \n",
    "        # Retrieve weather data\n",
    "        weather_video = self.weather_xr.sel(time = slice(start_date + np.timedelta64(1, \"D\"),\n",
    "                                                    end_date)) #slice include extremes\n",
    "        weather_video = weather_video.to_array().values\n",
    "        W = torch.from_numpy(weather_video).to(torch.float32)\n",
    "        \n",
    "        # Retrieve wtd values from t0+1 to T for the idx instance sensor\n",
    "        wtd_t1_T = self.wtd_df[[\"wtd\", \"nan_mask\"]].loc[(self.wtd_df.index.get_level_values(0) > start_date) &\n",
    "                                          (self.wtd_df.index.get_level_values(0) <= end_date)  & \n",
    "                                          (self.wtd_df.index.get_level_values(1) == sample_lat)&\n",
    "                                          (self.wtd_df.index.get_level_values(2) == sample_lon)]\n",
    "        \n",
    "        wtd_t1_T_values =  wtd_t1_T[\"wtd\"].values\n",
    "        wtd_t1_T_mask =  wtd_t1_T[\"nan_mask\"].values        \n",
    "        \n",
    "        Y = [torch.from_numpy(wtd_t1_T_values).to(torch.float32),\n",
    "             torch.from_numpy(wtd_t1_T_mask).to(torch.float32)]\n",
    "        \n",
    "        Y = torch.stack(Y, dim = -1)\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return [X, Z, W, Y]\n",
    "    \n",
    "    def get_weather_dtm(self):\n",
    "        return torch.from_numpy(self.weather_dtm).to(torch.float32)\n",
    "        \n",
    "    def get_weather_coords(self):\n",
    "        return torch.from_numpy(self.weather_coords).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_files = {\n",
    "#     \"wtd_csv_path\" : \"/leonardo_work/IscrC_DL4EO/trials/data/dataset_wtd_roi.csv\",\n",
    "#     \"weather_nc_path\" : \"/leonardo_work/IscrC_DL4EO/trials/data/meteo_bucket_model_snowpack_ROI_1958_2023.nc\",\n",
    "#     \"wtd_shp\" : \"/leonardo_work/IscrC_DL4EO/trials/data/shapefile/underground_wtd_sensor_roi.shp\",\n",
    "#     \"piedmont_shp\" : \"/leonardo_work/IscrC_DL4EO/trials/data/shapefile/piemonte_admin_boundaries.shp\",\n",
    "#     \"dtm_nc\" : \"/leonardo_work/IscrC_DL4EO/trials/data/dtm_ROI.nc\",\n",
    "#     \"timesteps\" : 180,\n",
    "#     \"weather_dtm\": \"/leonardo_work/IscrC_DL4EO/trials/data/dtm_ROI_arpa_weather.nc\"\n",
    "# }\n",
    "\n",
    "ds = ContinuousDataset(dict_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the dataset: 254820\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of the dataset: {ds.__len__()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "class Continuous1DNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 timestep = 180,\n",
    "                 cb_fc_layer = 5,\n",
    "                 cb_fc_neurons = 16,\n",
    "                 conv_filters = 16,\n",
    "                 lstm_layer = 3,\n",
    "                 lstm_input_units = 16,\n",
    "                 lstm_units = 32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.timestep = timestep\n",
    "        self.lstm_layer = lstm_layer\n",
    "        self.lstm_input_units = lstm_input_units\n",
    "        self.lstm_units = lstm_units\n",
    "        self.cb_fc_layer = cb_fc_layer\n",
    "        self.cb_fc_neurons = cb_fc_neurons\n",
    "        self.conv_filters = conv_filters\n",
    "        \n",
    "        # Conditioning block - gate fashion        \n",
    "                        # # Values embedding\n",
    "                        # cb_vemb = []\n",
    "                        # cb_vemb.append(nn.Linear(2, 1))\n",
    "                        # cb_vemb.append(nn.ReLU())\n",
    "                        # self.cb_vemb = nn.Sequential(*cb_vemb)\n",
    "                        # # Coordinates embedding\n",
    "                        # cb_cemb = []\n",
    "                        # cb_cemb.append(nn.Linear(3, 1))\n",
    "                        # cb_cemb.append(nn.ReLU())\n",
    "                        # self.cb_cemb = nn.Sequential(*cb_cemb)\n",
    "        \n",
    "        self.wgamma = nn.Sigmoid()\n",
    "        # Fully connected\n",
    "        cb_fc = []\n",
    "        cb_fc.append(nn.Linear(4, self.cb_fc_neurons))\n",
    "        cb_fc.append(nn.ReLU())\n",
    "        for l in range(self.cb_fc_layer - 2):\n",
    "            cb_fc.append(nn.Linear(self.cb_fc_neurons, self.cb_fc_neurons))\n",
    "            cb_fc.append(nn.ReLU())\n",
    "        \n",
    "        cb_fc.append(nn.Linear(self.cb_fc_neurons, self.lstm_units))\n",
    "        cb_fc.append(nn.ReLU())\n",
    "        self.cb_fc = nn.Sequential(*cb_fc)\n",
    "        \n",
    "        # Weather block\n",
    "        self.weather_wgamma = nn.Sigmoid()\n",
    "        \n",
    "        conv3d_stack=[]\n",
    "        conv3d_stack.append(nn.Conv3d(10, self.conv_filters, (1,2,2))) # Conv input (N, C, D, H, W) - kernel 3d (D, H, W)\n",
    "        conv3d_stack.append(nn.BatchNorm3d(self.conv_filters))\n",
    "        conv3d_stack.append(nn.ReLU())\n",
    "        \n",
    "        for i in range(4):\n",
    "            conv3d_stack.append(nn.Conv3d(self.conv_filters, self.conv_filters, (1,2,2)))\n",
    "            conv3d_stack.append(nn.BatchNorm3d(self.conv_filters))\n",
    "            conv3d_stack.append(nn.ReLU())\n",
    "            \n",
    "        conv3d_stack.append(nn.AdaptiveAvgPool3d((None,4,4)))\n",
    "        conv3d_stack.append(nn.Conv3d(self.conv_filters, self.conv_filters, (1,2,2)))\n",
    "        conv3d_stack.append(nn.BatchNorm3d(self.conv_filters))\n",
    "        conv3d_stack.append(nn.ReLU())\n",
    "        conv3d_stack.append(nn.Conv3d(self.conv_filters, self.conv_filters, (1,2,2)))\n",
    "        conv3d_stack.append(nn.BatchNorm3d(self.conv_filters))\n",
    "        conv3d_stack.append(nn.ReLU())\n",
    "        conv3d_stack.append(nn.Conv3d(self.conv_filters, self.lstm_input_units, (1,2,2)))\n",
    "        conv3d_stack.append(nn.BatchNorm3d(self.lstm_input_units))\n",
    "        conv3d_stack.append(nn.ReLU())\n",
    "        self.conv3d_stack = nn.Sequential(*conv3d_stack)\n",
    "            \n",
    "        # Joint sequental block\n",
    "        self.lstm_1 = nn.LSTM(self.lstm_input_units, self.lstm_units,\n",
    "                              batch_first=True,\n",
    "                              num_layers=self.lstm_layer) # Batch first input (N,L,H)\n",
    "        \n",
    "        fc = []\n",
    "        fc.append(nn.Linear(self.lstm_units, 8))\n",
    "        fc.append(nn.ReLU())\n",
    "        fc.append(nn.Linear(8, 1))\n",
    "        self.fc = nn.Sequential(*fc)\n",
    "\n",
    "\n",
    "    def forward(self, x, z, w):\n",
    "        \"\"\"\n",
    "        input : x (31, 5); z (1, 3); w[0] (10, 180, 9, 12); w[1] (9, 12, 3)\n",
    "        return \n",
    "            lstm_out (array): lstm_out = [S_we, M, P_r, Es, K_s, K_r]\n",
    "        x: tensor of shape (L,Hin) if minibatches itaration (L,N,Hin) when batch_first=False (default)\n",
    "        \"\"\"\n",
    "        \n",
    "        # #x (31, 5); z (3); w[0] (10, 180, 9, 12); w[1] (9, 12, 3); y (180, 2)\n",
    "        # [wtd_t0_lat, wtd_t0_lon,\n",
    "        #  wtd_t0_dtm, wtd_t0_values,\n",
    "        #  wtd_t0_mask] = x\n",
    "        \n",
    "        # [sample_lat, sample_lon, sample_dtm] = z\n",
    "        \n",
    "        # Conditioning block\n",
    "        \n",
    "        wtd_sim = torch.matmul(x[:,:,:3], z)\n",
    "        wtd_sim = self.wgamma(wtd_sim)\n",
    "        \n",
    "        wtd0 = torch.sum(x[:,:,:-1] * wtd_sim, dim = -1)/torch.sum(wtd_sim, dim = -1)\n",
    "        wtd0 = torch.cat([z, wtd0], dim = -1)\n",
    "        \n",
    "        wtd0 = self.cb_fc(wtd0)\n",
    "        \n",
    "        # Weather block\n",
    "        ## w[0] (10, 180, 9, 12); w[1] (9, 12, 3)\n",
    "        weather_sim = w[1] * z[:,None,None,:].expand(-1, w[1].shape[1], w[1].shape[2], -1)\n",
    "        weather_sim = torch.sum(weather_sim, dim = -1)\n",
    "        weather_sim = self.weather_wgamma(weather_sim)\n",
    "        weather = w[0] * weather_sim\n",
    "        \n",
    "        wb_td3dconv = self.conv3d_stack(weather)\n",
    "        \n",
    "        wb_td3dconv = wb_td3dconv.squeeze()\n",
    "        wb_td3dconv = torch.moveaxis(wb_td3dconv, 1, -1)\n",
    "        \n",
    "        # Sequential block\n",
    "        wtd0 = wtd0.unsqueeze(1).expand([-1,self.lstm_layer,-1])\n",
    "        wtd0 = torch.movedim(wtd0, 0, 1)\n",
    "        \n",
    "        wtd_series = self.lstm_1(wb_td3dconv,\n",
    "                                 (wtd0.contiguous(),\n",
    "                                  wtd0.contiguous())) #input  [input, (h_0, c_0)] - h and c (D∗num_layers,N,H)\n",
    "        \n",
    "        wtd_series = self.fc(wtd_series[0])\n",
    "        \n",
    "        return wtd_series.squeeze()\n",
    "\n",
    "model = Continuous1DNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parameters:  33201\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of trainable parameters: \" ,sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = dict_files[\"batch_size\"]\n",
    "max_epochs = dict_files[\"epochs\"]\n",
    "\n",
    "test_split_p = dict_files[\"test_split_p\"]\n",
    "train_split_p = 1 - test_split_p\n",
    "\n",
    "max_ds_elems = ds.__len__()\n",
    "if not dict_files[\"all_dataset\"]:\n",
    "    max_ds_elems = dict_files[\"max_ds_elems\"]\n",
    "\n",
    "train_idx = int(max_ds_elems*train_split_p)\n",
    "test_idx = int(max_ds_elems*test_split_p)\n",
    "\n",
    "print(f\"Traing size: {train_idx}, Test size: {test_idx}\")\n",
    "\n",
    "train_idxs, test_idxs = np.arange(train_idx), np.arange(train_idx, train_idx + test_idx)\n",
    "\n",
    "train_sampler = SequentialSampler(train_idxs)\n",
    "test_sampler = SequentialSampler(test_idxs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=ds,\n",
    "                                            batch_size=batch_size,\n",
    "                                            sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=ds,\n",
    "                                            batch_size=batch_size,\n",
    "                                            sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(x, y, y_hat, save_dir = None):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.suptitle(\"Loss vs iterations\")\n",
    "    ax.plot(x, y_hat, label = \"predicted\")\n",
    "    ax.plot(x, y, label = \"true\")\n",
    "    ax.legend()\n",
    "    if save_dir:\n",
    "        plt.savefig(f\"{save_dir}.png\", bbox_inches = 'tight') #dpi = 400, transparent = True\n",
    "    else:\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse(y_hat, y, mask):\n",
    "    # y_hat = y_hat.to(device)\n",
    "    # y = y.to(device)\n",
    "    # mask = mask.to(device)\n",
    "    return torch.sum(((y_hat-y)*mask)**2.0)  / torch.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    entity=\"gsartor-unito\",\n",
    "    project=dict_files[\"experiment_name\"],\n",
    "    dir =dict_files[\"wandb_dir\"],\n",
    "    config=dict_files,\n",
    "    mode=\"offline\",\n",
    ")\n",
    "\n",
    "# Magic\n",
    "wandb.watch(model, log_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/8038 [00:03<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch mem allocated in MB:  0.0\n",
      "After predict mem allocated in MB:  0.0\n",
      "tensor(355.8158, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 1/8038 [00:12<22:46:06, 10.20s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch mem allocated in MB:  0.0\n",
      "After predict mem allocated in MB:  0.0\n",
      "tensor(517.5479, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 1/8038 [00:14<33:22:57, 14.95s/batch]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 30\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n\u001b[1;32m     27\u001b[0m loss_list\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m---> 30\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (batch_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/leonardo_work/IscrC_DL4EO/my_venv/lib/python3.11/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/leonardo_work/IscrC_DL4EO/my_venv/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/leonardo_work/IscrC_DL4EO/my_venv/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "#save_dir = \"/leonardo_scratch/fast/IscrC_DL4EO/github/water-pinns/src/runs/continuous_1d\"\n",
    "\n",
    "weather_coords = ds.get_weather_coords()\n",
    "weather_dtm = ds.get_weather_dtm()\n",
    "weather_coords = torch.cat([weather_coords, weather_dtm], dim = -1)\n",
    "\n",
    "print('mem allocated in MB: ', torch.cuda.memory_allocated() / 1024**2)\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "\n",
    "for i in range(max_epochs):\n",
    "    \n",
    "    model.train(True)\n",
    "    start_time = time.time()\n",
    "    print(f\"############### Training epoch {i} ###############\")\n",
    "    \n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "            for batch_idx, (x, z, w_values, y) in enumerate(tepoch):\n",
    "                tepoch.set_description(f\"Epoch {i}\")\n",
    "                \n",
    "                x = x.to(device)\n",
    "                z = z.to(device)\n",
    "                w = [w_values.to(device), weather_coords.to(device)]\n",
    "                y = y.to(device)\n",
    "                #print('Batch mem allocated in MB: ', torch.cuda.memory_allocated() / 1024**2)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                y_hat = model(x, z, w)\n",
    "                #print('After predict mem allocated in MB: ', torch.cuda.memory_allocated() / 1024**2)\n",
    "                loss = masked_mse(y_hat,\n",
    "                                  y[:,:,0],\n",
    "                                  y[:,:,1])\n",
    "                \n",
    "                print(f\"Train loss: {loss}\")\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                metrics = {\n",
    "                    \"train_loss\" : loss\n",
    "                }\n",
    "                wandb.log(metrics)              \n",
    "                \n",
    "    end_time = time.time()\n",
    "    exec_time = end_time-start_time\n",
    "\n",
    "    wandb.log({\"tr_epoch_exec_t\" : exec_time})\n",
    "\n",
    "    model_path = 'model_{}_{}.pt'.format(timestamp, i)    \n",
    "    torch.save(model.state_dict(), f\"{dict_files[\"save_model_dir\"]}/{model_path}\") \n",
    "\n",
    "    print(f\"############### Test epoch {i} ###############\")\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
    "                for batch_idx, (x, z, w_values, y) in enumerate(tepoch):\n",
    "                    tepoch.set_description(f\"Epoch {i}\")\n",
    "\n",
    "                    x = x.to(device)\n",
    "                    z = z.to(device)\n",
    "                    w = [w_values.to(device), weather_coords.to(device)]\n",
    "                    y = y.to(device)\n",
    "                    # print('Batch mem allocated in MB: ', torch.cuda.memory_allocated() / 1024**2)\n",
    "\n",
    "                    y_hat = model(x, z, w)\n",
    "                    # print('After predict mem allocated in MB: ', torch.cuda.memory_allocated() / 1024**2)\n",
    "\n",
    "                    loss = masked_mse(y_hat,\n",
    "                                  y[:,:,0],\n",
    "                                  y[:,:,1])\n",
    "                    print(f\"Test loss: {loss}\")\n",
    "\n",
    "                    metrics = {\n",
    "                        \"test_loss\" : loss\n",
    "                    }\n",
    "\n",
    "                    wandb.log(metrics)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    exec_time = end_time-start_time\n",
    "    wandb.log({\"test_epoch_exec_t\" : exec_time})\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "print(f\"Execution time: {end_time-start_time}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
